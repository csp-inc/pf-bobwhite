{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deriving covariates across the northern bobwhite range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = date.today()\n",
    "import ee\n",
    "import math\n",
    "import geemap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# Initialize ee and authenticate \n",
    "#ee.Authenticate()\n",
    "ee.Initialize()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Important Information\n",
    "\n",
    "## Script name: \n",
    "\n",
    "## Purpose of script:\n",
    "This is a preliminary script for deriving covariates across the northern bobwhite range for use in the construction of a species distribution model.\n",
    "## Author: \n",
    "Patrick Freeman (CSP)\n",
    "## Date Created: \n",
    "04/25/23\n",
    "## Date last modified:\n",
    "print('Last Updated On: ', datetime.datetime.now())\n",
    "## Email: \n",
    "patrick[at]csp-inc.org\n",
    "## ---------------------------\n",
    "## Notes:\n",
    "\n",
    "## ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install geemap module as needed\n",
    "#!pip install geemap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ee\n",
    "import geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=Fa6urBC6KRVuV9LdYT4YOwdkiBylmdIGcAx0eM6Bd_g&tc=EIGykcAavMqyK6N6nZwYPsfrSYQYo0STyEn7ZvkHc6Y&cc=rh_5mX1KYr6ReQuPAAQDmBkgw2kS-zG07MWjfSpmcao>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=Fa6urBC6KRVuV9LdYT4YOwdkiBylmdIGcAx0eM6Bd_g&tc=EIGykcAavMqyK6N6nZwYPsfrSYQYo0STyEn7ZvkHc6Y&cc=rh_5mX1KYr6ReQuPAAQDmBkgw2kS-zG07MWjfSpmcao</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "\n",
    "# Focal mean\n",
    "def focal_mean(image, radius, unit, name):\n",
    "    names = image.bandNames().getInfo()\n",
    "    new_names = [s + name for s in names]\n",
    "    return image.reduceNeighborhood(kernel = ee.Kernel.circle(radius, unit),\n",
    "                                    reducer = ee.Reducer.mean()).rename(new_names)\n",
    "\n",
    "# Focal median\n",
    "def focal_median(image, radius, unit):\n",
    "    return image.reduceNeighborhood(kernel = ee.Kernel.circle(radius, unit),\n",
    "                                    reducer = ee.Reducer.median())\n",
    "    \n",
    "# Focal SD\n",
    "def focal_sd(image, radius, unit):\n",
    "    return image.reduceNeighborhood(kernel = ee.Kernel.circle(radius, unit),\n",
    "                                    reducer = ee.Reducer.stdDev())\n",
    "\n",
    "# Focal sum\n",
    "def focal_sum(image, radius, unit):\n",
    "    return image.reduceNeighborhood(kernel = ee.Kernel.circle(radius, unit, False),\n",
    "                                    reducer = ee.Reducer.sum())\n",
    "\n",
    "# Focal count\n",
    "def focal_count(image, radius, unit):\n",
    "    return image.reduceNeighborhood(kernel = ee.Kernel.circle(radius, unit, False),\n",
    "                                    reducer = ee.Reducer.count())\n",
    "    \n",
    "# Percent cover\n",
    "def percent_cov(image, radius, unit, name):\n",
    "    names = image.bandNames().getInfo()\n",
    "    new_names = [s + name for s in names]\n",
    "    isum = focal_sum(image, radius, unit)\n",
    "    icount = focal_count(image, radius, unit)\n",
    "    return isum.divide(icount).rename(new_names)\n",
    "\n",
    "def toFloat(img):\n",
    "    return img.float()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set aoi, spatial scale and projection of export, and smoothing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bring in buffered range map as 'region' \n",
    "region = ee.FeatureCollection('projects/GEE_CSP/pf-bobwhite/bobwhite_model_states')\n",
    "geometry = ee.Feature(ee.FeatureCollection(region).first())\n",
    "conus_geom = ee.FeatureCollection(\"projects/GEE_CSP/thirty-by-thirty/aoi_conus\")\n",
    "conus_img = ee.Image(\"projects/GEE_CSP/thirty-by-thirty/aoi_conus_mask\")\n",
    "\n",
    "# export scale and projection\n",
    "scale = 270\n",
    "projection = ee.Projection('EPSG:5070') # stand-in for now. Figure out best projection to use \n",
    "\n",
    "# Choose radii for summarizing covariates\n",
    "rad_large = 10000\n",
    "rad_small = 5000\n",
    "name_large = \"_10km\"\n",
    "name_small = \"_5km\"\n",
    "\n",
    "## Plot to check \n",
    "#Map = geemap.Map(center=(40, -100), zoom=4)\n",
    "#Map.addLayer(geometry, {}, \"Model states\", True)\n",
    "#Map\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSP-derived land use intensity layers related to agriculture, transportation, urban development, and energy infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lui Band names: ['Ag', 'Urban', 'Transport', 'Energy']\n",
      "lui_focal_means Band names: ['Ag_10km', 'Urban_10km', 'Transport_10km', 'Energy_10km']\n"
     ]
    }
   ],
   "source": [
    "lui = ee.Image(\"projects/GEE_CSP/aft-connectivity/Land-use-intensity-multiband-focal-sp-250m-20220123\")\n",
    "\n",
    "### Get the band names as a check \n",
    "lui_names = lui.bandNames()\n",
    "print('lui Band names:', lui_names.getInfo())  # ee.List of band names\n",
    "lui_focal_means_large = focal_mean(lui, rad_large, \"meters\", name_large).updateMask(conus_img).clip(geometry)\n",
    "lui_focal_means_small = focal_mean(lui, rad_small, \"meters\", name_small).updateMask(conus_img).clip(geometry)\n",
    "\n",
    "### Get the band names as a check \n",
    "lui_focal_means_names = lui_focal_means_large.bandNames()\n",
    "print('lui_focal_means Band names:', lui_focal_means_names.getInfo())  # ee.List of band names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate percent cover of row crop from NLCD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products: ['2001', '2004', '2006', '2008', '2011', '2013', '2016', '2019']\n",
      "rowcrop_pcov_all_band_names Band names: ['rowcrop_16_pcov_5km', 'rowcrop_19_pcov_5km']\n"
     ]
    }
   ],
   "source": [
    "### Load all NLCD layers from data release \n",
    "nlcd_all = ee.ImageCollection('USGS/NLCD_RELEASES/2019_REL/NLCD')\n",
    "\n",
    "### The collection contains images for multiple years and regions in the USA.\n",
    "print('Products:', nlcd_all.aggregate_array('system:index').getInfo())\n",
    "\n",
    "nlcd_16 = ee.ImageCollection(\"USGS/NLCD_RELEASES/2019_REL/NLCD\").filter(ee.Filter.eq('system:index', '2016')).first().select('landcover')\n",
    "nlcd_19 = ee.ImageCollection(\"USGS/NLCD_RELEASES/2019_REL/NLCD\").filter(ee.Filter.eq('system:index', '2019')).first().select('landcover')\n",
    "\n",
    "ag_16 = ee.Image(0).where(nlcd_16.eq(82), 1).rename('rowcrop_16')\n",
    "ag_19 = ee.Image(0).where(nlcd_19.eq(82), 1).rename('rowcrop_19')\n",
    "\n",
    "ag_all = ee.Image([ag_16, ag_19])\n",
    "\n",
    "rowcrop_pcov_all = percent_cov(ag_all, rad_small, 'meters', '_pcov' + name_small).clip(geometry)\n",
    "\n",
    "rowcrop_pcov_all_band_names = rowcrop_pcov_all.bandNames()\n",
    "print('rowcrop_pcov_all_band_names Band names:', rowcrop_pcov_all_band_names.getInfo())  # ee.List of band names\n",
    "\n",
    "rowcrop_pcov_avg = rowcrop_pcov_all.reduce(ee.Reducer.mean()).rename(['NLCD_1619_mean_rowcropPcov'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export ag proportional cover as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAP Proportional Cover - first calculate multi-year averages and apply smoothing within 5km smoothing windows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "band_names: ['2016_AFG', '2016_PFG', '2016_SHR', '2016_TRE', '2016_BGR', '2017_AFG', '2017_PFG', '2017_SHR', '2017_TRE', '2017_BGR', '2018_AFG', '2018_PFG', '2018_SHR', '2018_TRE', '2018_BGR', '2019_AFG', '2019_PFG', '2019_SHR', '2019_TRE', '2019_BGR', '2020_AFG', '2020_PFG', '2020_SHR', '2020_TRE', '2020_BGR', '2021_AFG', '2021_PFG', '2021_SHR', '2021_TRE', '2021_BGR']\n",
      "tree_mean_smooth Band names: ['RAP_TRE_1621_mean_5km']\n"
     ]
    }
   ],
   "source": [
    "geometry = ee.Feature(ee.FeatureCollection(\"projects/GEE_CSP/pf-bobwhite/bobwhite_model_states\").first());\n",
    "##---------- Define the years that you want to export --------------\n",
    "##---------- End year is inclusive in this case  ------------------\n",
    "yearStart = 2016\n",
    "yearEnd = 2021\n",
    "\n",
    "## -------------- Define the plant functional types (PFTs) that you want to export --------------\n",
    "## PFTs are \"AFGC\" (Annual forb and grass cover), \"BG\" (bare ground), \"LTR\" (litter), \n",
    "## \"PFGC\" (perennial forb and grass cover), \"SHR\" (shrub cover), and \"TREE\" (tree cover)\n",
    "## Select Annual forb and grass cover, perennial forb and grass cover, shrub cover, and tree cover \n",
    "PFTs = ee.List(['AFG', 'PFG', 'SHR', 'TRE', 'BGR'])\n",
    "\n",
    "cover = ee.ImageCollection(\"projects/rangeland-analysis-platform/vegetation-cover-v3\")\n",
    "## ------------- Select the PFTs for processing as defined by User  --------------\n",
    "cover_toExport = cover.select(PFTs).filter(ee.Filter.inList('year', ee.List([2016, 2017, 2018, 2019, 2020, 2021]))).toBands()\n",
    "\n",
    "band_names = cover_toExport.bandNames()\n",
    "print('band_names:', band_names.getInfo())  # ee.List of band names\n",
    "\n",
    "# Define string to match\n",
    "string_to_match = \"_TRE\"\n",
    "# Get the band names from the image\n",
    "band_names = cover_toExport.bandNames()\n",
    "# Filter the bands to select only the ones that contain the partial string\n",
    "tree_bands = band_names.filter(ee.Filter.stringContains(\"item\", string_to_match))\n",
    "# Select the TREE COVER bands from the image, calculate the multi-year mean, and apply the focal smooth operation\n",
    "tree_img = cover_toExport.select(tree_bands).reduce(ee.Reducer.mean()).rename(['RAP_TRE_1621_mean'])\n",
    "\n",
    "tree_mean_smooth = focal_mean(tree_img, rad_small, \"meters\", name_small).clip(geometry)\n",
    "tree_mean_smooth_band_names = tree_mean_smooth.bandNames()\n",
    "print('tree_mean_smooth Band names:', tree_mean_smooth_band_names.getInfo())  # ee.List of band names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shrub_mean_smooth Band names: ['RAP_TRE_1621_mean_5km']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select the SHRUB COVER bands from the image\n",
    "string_to_match = \"_SHR\"\n",
    "# Filter the bands to select only the ones that contain the partial string\n",
    "shrub_bands = band_names.filter(ee.Filter.stringContains(\"item\", string_to_match))\n",
    "# Select the SHRUB COVER bands from the image\n",
    "shrub_img = cover_toExport.select(shrub_bands).reduce(ee.Reducer.mean()).rename(['RAP_SHR_1621_mean'])\n",
    "\n",
    "shrub_mean_smooth = focal_mean(shrub_img, rad_small, \"meters\", name_small).clip(geometry)\n",
    "shrub_mean_smooth_band_names = shrub_mean_smooth.bandNames()\n",
    "print('shrub_mean_smooth Band names:', shrub_mean_smooth_band_names.getInfo())  # ee.List of band names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afg_mean_smooth Band names: ['RAP_AFG_1621_mean_5km']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select the ANNUAL FORB AND GRASS COVER bands from the image\n",
    "string_to_match = \"_AFG\"\n",
    "# Filter the bands to select only the ones that contain the partial string\n",
    "afg_bands = band_names.filter(ee.Filter.stringContains(\"item\", string_to_match))\n",
    "afg_img = cover_toExport.select(afg_bands).reduce(ee.Reducer.mean()).rename(['RAP_AFG_1621_mean'])\n",
    "\n",
    "afg_mean_smooth = focal_mean(afg_img, rad_small, \"meters\", name_small).clip(geometry)\n",
    "afg_mean_smooth_band_names = afg_mean_smooth.bandNames()\n",
    "print('afg_mean_smooth Band names:', afg_mean_smooth_band_names.getInfo())  # ee.List of band names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pfg_mean_smooth Band names: ['RAP_PFG_1621_mean_5km']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select the PERENNIAL FORB AND GRASS COVER bands from the image\n",
    "string_to_match = \"_PFG\"\n",
    "# Filter the bands to select only the ones that contain the partial string\n",
    "pfg_bands = band_names.filter(ee.Filter.stringContains(\"item\", string_to_match))\n",
    "# Select the ANNUAL FORB AND GRASS COVER bands from the image\n",
    "pfg_img = cover_toExport.select(pfg_bands).reduce(ee.Reducer.mean()).rename(['RAP_PFG_1621_mean'])\n",
    "\n",
    "pfg_mean_smooth = focal_mean(pfg_img, rad_small, \"meters\", name_small).clip(geometry)\n",
    "pfg_mean_smooth_band_names = pfg_mean_smooth.bandNames()\n",
    "print('pfg_mean_smooth Band names:', pfg_mean_smooth_band_names.getInfo())  # ee.List of band names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bgr_mean_smooth Band names: ['RAP_BGR_1621_mean_5km']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select the BARE GROUND COVER bands from the image\n",
    "string_to_match = \"_BGR\"\n",
    "# Filter the bands to select only the ones that contain the partial string\n",
    "bgr_bands = band_names.filter(ee.Filter.stringContains(\"item\", string_to_match))\n",
    "# Select the ANNUAL FORB AND GRASS COVER bands from the image\n",
    "bgr_img = cover_toExport.select(bgr_bands).reduce(ee.Reducer.mean()).rename(['RAP_BGR_1621_mean'])\n",
    "\n",
    "bgr_mean_smooth = focal_mean(bgr_img, rad_small, \"meters\", name_small).clip(geometry)\n",
    "bgr_mean_smooth_band_names = bgr_mean_smooth.bandNames()\n",
    "print('bgr_mean_smooth Band names:', bgr_mean_smooth_band_names.getInfo())  # ee.List of band names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect the raw (unsmoothed) multi-year average RAP cover images into a multi-band image for gradient analysis  - export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RAP_unsmoothed = ee.Image([tree_img, shrub_img, afg_img, pfg_img, bgr_img ])\n",
    "\n",
    "# Convert all to float-32\n",
    "RAP_unsmoothed = RAP_unsmoothed.float()\n",
    "scale=270\n",
    "task1 = ee.batch.Export.image.toDrive(image = RAP_unsmoothed,\n",
    "                                     folder = 'GEE-exports',\n",
    "                                     description = 'RAP-1621-mean-unsmoothed' + str(scale) + \"m\",\n",
    "                                     scale = scale,\n",
    "                                     region = geometry.geometry(),\n",
    "                                     maxPixels = 1e13,\n",
    "                                     crs = \"EPSG:5070\")\n",
    "task1.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Filter RAP cover ImageCollection into yearly sets\n",
    "rap_cover_2016 = cover_toExport.filter(ee.Filter.inList('year', ee.List([2016]))).toBands()\n",
    "rap_cover_2017 = cover_toExport.filter(ee.Filter.inList('year', ee.List([2017]))).toBands()\n",
    "rap_cover_2018 = cover_toExport.filter(ee.Filter.inList('year', ee.List([2018]))).toBands()\n",
    "rap_cover_2019 = cover_toExport.filter(ee.Filter.inList('year', ee.List([2019]))).toBands()\n",
    "rap_cover_2021 = cover_toExport.filter(ee.Filter.inList('year', ee.List([2021]))).toBands()\n",
    "\n",
    "### Combine all into single multiband image \n",
    "rap_cover_all = ee.Image([rap_cover_2016, rap_cover_2017, rap_cover_2018, rap_cover_2019, rap_cover_2021])\n",
    "\n",
    "rap_cover_all_band_names = rap_cover_all.bandNames()\n",
    "#print('rap_cover_2016 Band names:', rap_cover_all_band_names.getInfo())  # ee.List of band names\n",
    "\n",
    "### Apply focal mean smoothing\n",
    "rap_cover_all_small = focal_mean(rap_cover_all, rad_small, \"meters\", name_small).clip(geometry)\n",
    "rap_cover_all_small_band_names = rap_cover_all_small.bandNames()\n",
    "print('rap_cover_all_small Band names:', rap_cover_all_small_band_names.getInfo())  # ee.List of band names\n",
    "\n",
    "b1scale = rap_cover_2016.select('2016_AFG').projection().nominalScale()\n",
    "b1projection = rap_cover_2016.select('2016_AFG').projection()\n",
    "\n",
    "print('Band 1 scale: ', b1scale.getInfo())\n",
    "print('Band 1 projection: ', b1projection.getInfo())\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate covariates from Daymet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load daymet dataset \n",
    "daymet_16 = ee.ImageCollection(\"NASA/ORNL/DAYMET_V4\").filter(ee.Filter.date('2016-01-01', '2016-12-31'))\n",
    "daymet_17 = ee.ImageCollection(\"NASA/ORNL/DAYMET_V4\").filter(ee.Filter.date('2017-01-01', '2017-12-31'))\n",
    "daymet_18 = ee.ImageCollection(\"NASA/ORNL/DAYMET_V4\").filter(ee.Filter.date('2018-01-01', '2018-12-31'))\n",
    "daymet_19 = ee.ImageCollection(\"NASA/ORNL/DAYMET_V4\").filter(ee.Filter.date('2019-01-01', '2019-12-31'))\n",
    "daymet_21 = ee.ImageCollection(\"NASA/ORNL/DAYMET_V4\").filter(ee.Filter.date('2021-01-01', '2021-12-31'))\n",
    "\n",
    "daymet_1621 = ee.ImageCollection(\"NASA/ORNL/DAYMET_V4\").filter(ee.Filter.date('2016-01-01', '2021-12-31'))\n",
    "tmax_1621 = daymet_1621.select(\"tmax\").mean().rename(['tmax_1621_mean'])\n",
    "tmin_1621 = daymet_1621.select(\"tmin\").mean().rename(['tmin_1621_mean'])\n",
    "prcp_1621 = daymet_1621.select(\"prcp\").mean().rename(['prcp_1621_mean'])\n",
    "swe_1621 = daymet_1621.select(\"swe\").mean().rename(['swe_1621_mean'])\n",
    "\n",
    "climate_1621 = ee.Image([tmax_1621, tmin_1621, prcp_1621, swe_1621])\n",
    "climate_1621_small = focal_mean(climate_1621, rad_small, \"meters\", name_small).updateMask(conus_img).clip(geometry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert all to float-32\n",
    "climate_1621_small = climate_1621_small.float()\n",
    "scale=270\n",
    "task1 = ee.batch.Export.image.toDrive(image = climate_1621_small,\n",
    "                                     folder = 'GEE-exports',\n",
    "                                     description = 'climate-1621-mean-unsmoothed' + str(scale) + \"m\",\n",
    "                                     scale = scale,\n",
    "                                     region = geometry.geometry(),\n",
    "                                     maxPixels = 1e13,\n",
    "                                     crs = \"EPSG:5070\")\n",
    "task1.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "### mean daily max temperature\n",
    "tmax_16 = daymet_16.select(\"tmax\").mean().clip(geometry).rename(['tmax_16'])\n",
    "tmax_17 = daymet_17.select(\"tmax\").mean().clip(geometry).rename(['tmax_17'])\n",
    "tmax_18 = daymet_18.select(\"tmax\").mean().clip(geometry).rename(['tmax_18'])\n",
    "tmax_19 = daymet_19.select(\"tmax\").mean().clip(geometry).rename(['tmax_19'])\n",
    "tmax_21 = daymet_21.select(\"tmax\").mean().clip(geometry).rename(['tmax_21'])\n",
    "\n",
    "### mean daily min temperature\n",
    "tmin_16 = daymet_16.select(\"tmin\").mean().clip(geometry).rename(['tmin_16'])\n",
    "tmin_17 = daymet_17.select(\"tmin\").mean().clip(geometry).rename(['tmin_17'])\n",
    "tmin_18 = daymet_18.select(\"tmin\").mean().clip(geometry).rename(['tmin_18'])\n",
    "tmin_19 = daymet_19.select(\"tmin\").mean().clip(geometry).rename(['tmin_19'])\n",
    "tmin_21 = daymet_21.select(\"tmin\").mean().clip(geometry).rename(['tmin_21'])\n",
    "\n",
    "### mean daily precip\n",
    "prcp_16 = daymet_16.select(\"prcp\").mean().clip(geometry).rename(['prcp_16'])\n",
    "prcp_17 = daymet_17.select(\"prcp\").mean().clip(geometry).rename(['prcp_17'])\n",
    "prcp_18 = daymet_18.select(\"prcp\").mean().clip(geometry).rename(['prcp_18'])\n",
    "prcp_19 = daymet_19.select(\"prcp\").mean().clip(geometry).rename(['prcp_19'])\n",
    "prcp_21 = daymet_21.select(\"prcp\").mean().clip(geometry).rename(['prcp_21'])\n",
    "\n",
    "### mean daily snow water equivalent\n",
    "swe_16 = daymet_16.select(\"swe\").mean().clip(geometry).rename(['swe_16'])\n",
    "swe_17 = daymet_17.select(\"swe\").mean().clip(geometry).rename(['swe_17'])\n",
    "swe_18 = daymet_18.select(\"swe\").mean().clip(geometry).rename(['swe_18'])\n",
    "swe_19 = daymet_19.select(\"swe\").mean().clip(geometry).rename(['swe_19'])\n",
    "swe_21 = daymet_21.select(\"swe\").mean().clip(geometry).rename(['swe_21'])\n",
    "\n",
    "climate_all = ee.Image([ tmax_16, tmax_17, tmax_18, tmax_19, tmax_21, tmin_16, tmin_17, tmin_18, tmin_19, tmin_21, \n",
    "                        prcp_16, prcp_17, prcp_18, prcp_19, prcp_21, swe_16, swe_17, swe_18, swe_19, swe_21])\n",
    "\n",
    "climate_small = focal_mean(climate_all, rad_small, \"meters\", name_small).updateMask(conus_img).clip(geometry)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract values at grid cell centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Feature', 'geometry': {'type': 'Point', 'coordinates': [-89.10796927232737, 47.9018434831802]}, 'id': '0000000000000000e1bf', 'properties': {'grid_id_5k': 43}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Load sampling grid\n",
    "grid_5km = ee.FeatureCollection(\"projects/GEE_CSP/pf-bobwhite/grid_5km\")\n",
    "\n",
    "# Define a function to extract the centroid of a feature and create a new feature with that centroid as its geometry\n",
    "def get_centroid(feature):\n",
    "    keepProperties = ['grid_id_5k']\n",
    "    centroid = feature.geometry().centroid()\n",
    "    return ee.Feature(centroid).copyProperties(feature, keepProperties)\n",
    "\n",
    "# Map the get_centroid function over the FeatureCollection to create a new FeatureCollection containing just the centroids\n",
    "centroids = grid_5km.map(get_centroid)\n",
    "\n",
    "# Print the result\n",
    "print(centroids.first().getInfo())\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1: Feature extraction using reduceRegion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract RAP proportional cover to CSV - this exports just fine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Write function to perform the raster extraction (for each raster) -- importantly set scale to the native resolution of whatever raster you're extracting from (e.g. 30m for RAP, 250m for LUI, etc.)\n",
    "def extract_rap_values(feature):\n",
    "  # Get the geometry of the feature\n",
    "  geometry = feature.geometry()\n",
    "\n",
    "  # Extract the raster values for the feature\n",
    "  values = rap_cover_all_small.reduceRegion(\n",
    "      reducer=ee.Reducer.mean(),\n",
    "      geometry=geometry,\n",
    "      scale=30)\n",
    "\n",
    "  # Set the values as properties of the feature\n",
    "  return feature.set(values)\n",
    "\n",
    "# Map the extract_values function over the feature collection\n",
    "rap_results = centroids.map(extract_rap_values)\n",
    "\n",
    "\n",
    "# Export the feature collection as a CSV file\n",
    "task = ee.batch.Export.table.toDrive(\n",
    "    collection=rap_results,\n",
    "    description='RAP-export',\n",
    "    folder='GEE_exports',\n",
    "    fileNamePrefix='RAP_5km',\n",
    "    fileFormat='CSV')\n",
    "task.start()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract gradient metric values to csv - ARGH I CANNOT GET THIS TO EXPORT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099f42159fab40d1a0294537725a5573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Hansen image for access to water mask\n",
    "hansenImage = ee.Image(\"UMD/hansen/global_forest_change_2021_v1_9\")\n",
    "# Select the land/water mask.\n",
    "datamask = hansenImage.select('datamask')\n",
    "\n",
    "#Create a binary mask.\n",
    "mask = datamask.eq(1)\n",
    "\n",
    "rap_cover_2016 = cover_toExport.filter(ee.Filter.inList('year', ee.List([2016]))).toBands()\n",
    "\n",
    "rap_cover_2016_mask = rap_cover_2016.updateMask(mask)\n",
    "\n",
    "test = rap_cover_2016_mask.select('2016_TRE')\n",
    "rap_vis = {\n",
    "    'min': 0,\n",
    "    'max': 100,\n",
    "}\n",
    "\n",
    "Map = geemap.Map()\n",
    "Map.addLayer(test, rap_vis, '2016 Tree Cover');\n",
    "Map\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_gradient_values(feature):\n",
    "  # Get the geometry of the feature\n",
    "  geometry = feature.geometry()\n",
    "\n",
    "  # Extract the raster values for the feature\n",
    "  values = sa_img_16.reduceRegion(\n",
    "      reducer=ee.Reducer.mean(),\n",
    "      geometry=geometry)\n",
    "  # Set the values as properties of the feature\n",
    "  return feature.set(values)\n",
    "\n",
    "gradient_results = centroids.map(extract_gradient_values)\n",
    "\n",
    "# Export the feature collection as a CSV file\n",
    "task = ee.batch.Export.table.toDrive(\n",
    "    collection=gradient_results,\n",
    "    description='RAP-SA-export',\n",
    "    folder='GEE_exports',\n",
    "    fileNamePrefix='RAP_2016_SA_5km',\n",
    "    fileFormat='CSV')\n",
    "task.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract DAYMET climate values to csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_climate_values(feature):\n",
    "  # Get the geometry of the feature\n",
    "  geometry = feature.geometry()\n",
    "\n",
    "  # Extract the raster values for the feature\n",
    "  values = climate_small.reduceRegion(\n",
    "      reducer=ee.Reducer.mean(),\n",
    "      geometry=geometry)\n",
    "  # Set the values as properties of the feature\n",
    "  return feature.set(values)\n",
    "\n",
    "climate_results = centroids.map(extract_climate_values)\n",
    "\n",
    "# Export the feature collection as a CSV file\n",
    "task = ee.batch.Export.table.toDrive(\n",
    "    collection=climate_results,\n",
    "    description='daymet-climate-export',\n",
    "    folder='GEE_exports',\n",
    "    fileNamePrefix='daymet_climate_5km',\n",
    "    fileFormat='CSV')\n",
    "task.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract values to points using geemap function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = os.path.expanduser(\"~/Downloads\")\n",
    "out_csv = os.path.join(work_dir, \"RAP_2016_5km_TREsa_out.csv\")\n",
    "\n",
    "geemap.extract_values_to_points(\n",
    "    centroids,\n",
    "    tree_sa_16,\n",
    "    out_csv,\n",
    "    scale = 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "722949c11c1062be71c011a99f617ef2cb85f305dcd033156e357c49092a513e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
