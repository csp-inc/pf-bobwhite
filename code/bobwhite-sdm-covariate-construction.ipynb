{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deriving covariates across the northern bobwhite range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = date.today()\n",
    "import ee\n",
    "import math\n",
    "import geemap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# Initialize ee and authenticate \n",
    "#ee.Authenticate()\n",
    "ee.Initialize()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Important Information\n",
    "\n",
    "## Script name: \n",
    "\n",
    "## Purpose of script:\n",
    "This is a preliminary script for deriving covariates across the northern bobwhite range for use in the construction of a species distribution model.\n",
    "## Author: \n",
    "Patrick Freeman (CSP)\n",
    "## Date Created: \n",
    "04/25/23\n",
    "## Date last modified:\n",
    "print('Last Updated On: ', datetime.datetime.now())\n",
    "## Email: \n",
    "patrick[at]csp-inc.org\n",
    "## ---------------------------\n",
    "## Notes:\n",
    "\n",
    "## ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install geemap module as needed\n",
    "#!pip install geemap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ee\n",
    "import geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=Fa6urBC6KRVuV9LdYT4YOwdkiBylmdIGcAx0eM6Bd_g&tc=EIGykcAavMqyK6N6nZwYPsfrSYQYo0STyEn7ZvkHc6Y&cc=rh_5mX1KYr6ReQuPAAQDmBkgw2kS-zG07MWjfSpmcao>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=Fa6urBC6KRVuV9LdYT4YOwdkiBylmdIGcAx0eM6Bd_g&tc=EIGykcAavMqyK6N6nZwYPsfrSYQYo0STyEn7ZvkHc6Y&cc=rh_5mX1KYr6ReQuPAAQDmBkgw2kS-zG07MWjfSpmcao</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "\n",
    "# Focal mean\n",
    "def focal_mean(image, radius, unit, name):\n",
    "    names = image.bandNames().getInfo()\n",
    "    new_names = [s + name for s in names]\n",
    "    return image.reduceNeighborhood(kernel = ee.Kernel.circle(radius, unit),\n",
    "                                    reducer = ee.Reducer.mean()).rename(new_names)\n",
    "\n",
    "# Focal median\n",
    "def focal_median(image, radius, unit):\n",
    "    return image.reduceNeighborhood(kernel = ee.Kernel.circle(radius, unit),\n",
    "                                    reducer = ee.Reducer.median())\n",
    "    \n",
    "# Focal SD\n",
    "def focal_sd(image, radius, unit):\n",
    "    return image.reduceNeighborhood(kernel = ee.Kernel.circle(radius, unit),\n",
    "                                    reducer = ee.Reducer.stdDev())\n",
    "\n",
    "# Focal sum\n",
    "def focal_sum(image, radius, unit):\n",
    "    return image.reduceNeighborhood(kernel = ee.Kernel.circle(radius, unit, False),\n",
    "                                    reducer = ee.Reducer.sum())\n",
    "\n",
    "# Focal count\n",
    "def focal_count(image, radius, unit):\n",
    "    return image.reduceNeighborhood(kernel = ee.Kernel.circle(radius, unit, False),\n",
    "                                    reducer = ee.Reducer.count())\n",
    "    \n",
    "# Percent cover\n",
    "def percent_cov(image, radius, unit, name):\n",
    "    names = image.bandNames().getInfo()\n",
    "    new_names = [s + name for s in names]\n",
    "    isum = focal_sum(image, radius, unit)\n",
    "    icount = focal_count(image, radius, unit)\n",
    "    return isum.divide(icount).rename(new_names)\n",
    "\n",
    "# Define a function to calculate the Surface Roughness as the the mean absolute deviation of values from the mean within the window - window size is in meters \n",
    "def surface_sa(image, window_size, name):\n",
    "    names = image.bandNames().getInfo()\n",
    "    new_names = [s + name for s in names]\n",
    "    kernel = ee.Kernel.circle(radius=window_size, units='meters')\n",
    "    mean = image.reduceNeighborhood(ee.Reducer.mean(), kernel)\n",
    "    deviation = image.subtract(mean)\n",
    "    absolute_deviation = deviation.abs()\n",
    "    return absolute_deviation.reduceNeighborhood(ee.Reducer.mean(), kernel).rename(new_names)\n",
    "\n",
    "def toFloat(img):\n",
    "    return img.float()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set aoi, spatial scale and projection of export, and smoothing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bring in buffered range map as 'region' \n",
    "region = ee.FeatureCollection('projects/GEE_CSP/pf-bobwhite/bobwhite_model_states')\n",
    "geometry = ee.Feature(ee.FeatureCollection(region).first())\n",
    "conus_geom = ee.FeatureCollection(\"projects/GEE_CSP/thirty-by-thirty/aoi_conus\")\n",
    "conus_img = ee.Image(\"projects/GEE_CSP/thirty-by-thirty/aoi_conus_mask\")\n",
    "\n",
    "# export scale and projection\n",
    "scale = 250\n",
    "projection = ee.Projection('EPSG:5070') # stand-in for now. Figure out best projection to use \n",
    "\n",
    "# Choose radii for summarizing covariates\n",
    "rad_large = 10000\n",
    "rad_small = 5000\n",
    "name_large = \"_10km\"\n",
    "name_small = \"_5km\"\n",
    "\n",
    "## Plot to check \n",
    "#Map = geemap.Map(center=(40, -100), zoom=4)\n",
    "#Map.addLayer(geometry, {}, \"Model states\", True)\n",
    "#Map\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSP-derived land use intensity layers related to agriculture, transportation, urban development, and energy infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lui Band names: ['Ag', 'Urban', 'Transport', 'Energy']\n",
      "lui_focal_means Band names: ['Ag_10km', 'Urban_10km', 'Transport_10km', 'Energy_10km']\n"
     ]
    }
   ],
   "source": [
    "lui = ee.Image(\"projects/GEE_CSP/aft-connectivity/Land-use-intensity-multiband-focal-sp-250m-20220123\")\n",
    "\n",
    "### Get the band names as a check \n",
    "lui_names = lui.bandNames()\n",
    "print('lui Band names:', lui_names.getInfo())  # ee.List of band names\n",
    "lui_focal_means_large = focal_mean(lui, rad_large, \"meters\", name_large).updateMask(conus_img).clip(geometry)\n",
    "lui_focal_means_small = focal_mean(lui, rad_small, \"meters\", name_small).updateMask(conus_img).clip(geometry)\n",
    "\n",
    "### Get the band names as a check \n",
    "lui_focal_means_names = lui_focal_means_large.bandNames()\n",
    "print('lui_focal_means Band names:', lui_focal_means_names.getInfo())  # ee.List of band names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAP Proportional Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rap_cover_all_small Band names: ['2016_AFG_5km', '2016_PFG_5km', '2016_SHR_5km', '2016_TRE_5km', '2016_BGR_5km', '2017_AFG_5km', '2017_PFG_5km', '2017_SHR_5km', '2017_TRE_5km', '2017_BGR_5km', '2018_AFG_5km', '2018_PFG_5km', '2018_SHR_5km', '2018_TRE_5km', '2018_BGR_5km', '2019_AFG_5km', '2019_PFG_5km', '2019_SHR_5km', '2019_TRE_5km', '2019_BGR_5km', '2021_AFG_5km', '2021_PFG_5km', '2021_SHR_5km', '2021_TRE_5km', '2021_BGR_5km']\n",
      "Band 1 scale:  30.000000000000004\n",
      "Band 1 projection:  {'type': 'Projection', 'crs': 'EPSG:4326', 'transform': [0.00026949458523585647, 0, -124.76979458874112, 0, -0.00026949458523585647, 49.393776065783484]}\n"
     ]
    }
   ],
   "source": [
    "geometry = ee.Feature(ee.FeatureCollection(\"projects/GEE_CSP/pf-bobwhite/bobwhite_model_states\").first());\n",
    "##---------- Define the years that you want to export --------------\n",
    "##---------- End year is inclusive in this case  ------------------\n",
    "yearStart = 2016\n",
    "yearEnd = 2021\n",
    "\n",
    "## -------------- Define the plant functional types (PFTs) that you want to export --------------\n",
    "## PFTs are \"AFGC\" (Annual forb and grass cover), \"BG\" (bare ground), \"LTR\" (litter), \n",
    "## \"PFGC\" (perennial forb and grass cover), \"SHR\" (shrub cover), and \"TREE\" (tree cover)\n",
    "## Select Annual forb and grass cover, perennial forb and grass cover, shrub cover, and tree cover \n",
    "PFTs = ee.List(['AFG', 'PFG', 'SHR', 'TRE', 'BGR']);\n",
    "\n",
    "cover = ee.ImageCollection(\"projects/rangeland-analysis-platform/vegetation-cover-v3\")\n",
    "## ------------- Select the PFTs for processing as defined by User  --------------\n",
    "cover_toExport = cover.select(PFTs)\n",
    "\n",
    "\n",
    "### Filter RAP cover ImageCollection into yearly sets\n",
    "rap_cover_2016 = cover_toExport.filter(ee.Filter.inList('year', ee.List([2016]))).toBands()\n",
    "rap_cover_2017 = cover_toExport.filter(ee.Filter.inList('year', ee.List([2017]))).toBands()\n",
    "rap_cover_2018 = cover_toExport.filter(ee.Filter.inList('year', ee.List([2018]))).toBands()\n",
    "rap_cover_2019 = cover_toExport.filter(ee.Filter.inList('year', ee.List([2019]))).toBands()\n",
    "rap_cover_2021 = cover_toExport.filter(ee.Filter.inList('year', ee.List([2021]))).toBands()\n",
    "\n",
    "### Combine all into single multiband image \n",
    "rap_cover_all = ee.Image([rap_cover_2016, rap_cover_2017, rap_cover_2018, rap_cover_2019, rap_cover_2021])\n",
    "\n",
    "rap_cover_all_band_names = rap_cover_all.bandNames()\n",
    "#print('rap_cover_2016 Band names:', rap_cover_all_band_names.getInfo())  # ee.List of band names\n",
    "\n",
    "### Apply focal mean smoothing\n",
    "rap_cover_all_small = focal_mean(rap_cover_all, rad_small, \"meters\", name_small).clip(geometry)\n",
    "rap_cover_all_small_band_names = rap_cover_all_small.bandNames()\n",
    "print('rap_cover_all_small Band names:', rap_cover_all_small_band_names.getInfo())  # ee.List of band names\n",
    "\n",
    "b1scale = rap_cover_2016.select('2016_AFG').projection().nominalScale()\n",
    "b1projection = rap_cover_2016.select('2016_AFG').projection()\n",
    "\n",
    "print('Band 1 scale: ', b1scale.getInfo())\n",
    "print('Band 1 projection: ', b1projection.getInfo())\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate covariates from Daymet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load daymet dataset \n",
    "daymet_16 = ee.ImageCollection(\"NASA/ORNL/DAYMET_V4\").filter(ee.Filter.date('2016-01-01', '2016-12-31'))\n",
    "daymet_17 = ee.ImageCollection(\"NASA/ORNL/DAYMET_V4\").filter(ee.Filter.date('2017-01-01', '2017-12-31'))\n",
    "daymet_18 = ee.ImageCollection(\"NASA/ORNL/DAYMET_V4\").filter(ee.Filter.date('2018-01-01', '2018-12-31'))\n",
    "daymet_19 = ee.ImageCollection(\"NASA/ORNL/DAYMET_V4\").filter(ee.Filter.date('2019-01-01', '2019-12-31'))\n",
    "daymet_21 = ee.ImageCollection(\"NASA/ORNL/DAYMET_V4\").filter(ee.Filter.date('2021-01-01', '2021-12-31'))\n",
    "\n",
    "\n",
    "### mean daily max temperature\n",
    "tmax_16 = daymet_16.select(\"tmax\").mean().clip(geometry).rename(['tmax_16'])\n",
    "tmax_17 = daymet_17.select(\"tmax\").mean().clip(geometry).rename(['tmax_17'])\n",
    "tmax_18 = daymet_18.select(\"tmax\").mean().clip(geometry).rename(['tmax_18'])\n",
    "tmax_19 = daymet_19.select(\"tmax\").mean().clip(geometry).rename(['tmax_19'])\n",
    "tmax_21 = daymet_21.select(\"tmax\").mean().clip(geometry).rename(['tmax_21'])\n",
    "\n",
    "### mean daily min temperature\n",
    "tmin_16 = daymet_16.select(\"tmin\").mean().clip(geometry).rename(['tmin_16'])\n",
    "tmin_17 = daymet_17.select(\"tmin\").mean().clip(geometry).rename(['tmin_17'])\n",
    "tmin_18 = daymet_18.select(\"tmin\").mean().clip(geometry).rename(['tmin_18'])\n",
    "tmin_19 = daymet_19.select(\"tmin\").mean().clip(geometry).rename(['tmin_19'])\n",
    "tmin_21 = daymet_21.select(\"tmin\").mean().clip(geometry).rename(['tmin_21'])\n",
    "\n",
    "### mean daily precip\n",
    "prcp_16 = daymet_16.select(\"prcp\").mean().clip(geometry).rename(['prcp_16'])\n",
    "prcp_17 = daymet_17.select(\"prcp\").mean().clip(geometry).rename(['prcp_17'])\n",
    "prcp_18 = daymet_18.select(\"prcp\").mean().clip(geometry).rename(['prcp_18'])\n",
    "prcp_19 = daymet_19.select(\"prcp\").mean().clip(geometry).rename(['prcp_19'])\n",
    "prcp_21 = daymet_21.select(\"prcp\").mean().clip(geometry).rename(['prcp_21'])\n",
    "\n",
    "### mean daily snow water equivalent\n",
    "swe_16 = daymet_16.select(\"swe\").mean().clip(geometry).rename(['swe_16'])\n",
    "swe_17 = daymet_17.select(\"swe\").mean().clip(geometry).rename(['swe_17'])\n",
    "swe_18 = daymet_18.select(\"swe\").mean().clip(geometry).rename(['swe_18'])\n",
    "swe_19 = daymet_19.select(\"swe\").mean().clip(geometry).rename(['swe_19'])\n",
    "swe_21 = daymet_21.select(\"swe\").mean().clip(geometry).rename(['swe_21'])\n",
    "\n",
    "climate_all = ee.Image([ tmax_16, tmax_17, tmax_18, tmax_19, tmax_21, tmin_16, tmin_17, tmin_18, tmin_19, tmin_21, \n",
    "                        prcp_16, prcp_17, prcp_18, prcp_19, prcp_21, swe_16, swe_17, swe_18, swe_19, swe_21])\n",
    "\n",
    "climate_small = focal_mean(climate_all, rad_small, \"meters\", name_small).updateMask(conus_img).clip(geometry)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Analysis - Surface Roughness applied to RAP Proportional Cover dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sa_img_band_names: ['2016_AFG_5km_sa', '2016_PFG_5km_sa', '2016_SHR_5km_sa', '2016_TRE_5km_sa', '2016_BGR_5km_sa', '2017_AFG_5km_sa', '2017_PFG_5km_sa', '2017_SHR_5km_sa', '2017_TRE_5km_sa', '2017_BGR_5km_sa', '2018_AFG_5km_sa', '2018_PFG_5km_sa', '2018_SHR_5km_sa', '2018_TRE_5km_sa', '2018_BGR_5km_sa', '2019_AFG_5km_sa', '2019_PFG_5km_sa', '2019_SHR_5km_sa', '2019_TRE_5km_sa', '2019_BGR_5km_sa', '2021_AFG_5km_sa', '2021_PFG_5km_sa', '2021_SHR_5km_sa', '2021_TRE_5km_sa', '2021_BGR_5km_sa']\n"
     ]
    }
   ],
   "source": [
    "# Map the surface_sa function over the RAP image collection - calculate surface roughness in a moving window of 5000m radius\n",
    "sa_img = surface_sa(rap_cover_all, 5000, \"_5km_sa\").clip(geometry)\n",
    "\n",
    "sa_img_band_names = sa_img.bandNames()\n",
    "print('sa_img_band_names:', sa_img_band_names.getInfo())  # ee.List of band names\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract values at grid cell centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Feature', 'geometry': {'type': 'Point', 'coordinates': [-89.10796927232737, 47.9018434831802]}, 'id': '0000000000000000e1bf', 'properties': {'grid_id_5k': 43}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Load sampling grid\n",
    "grid_5km = ee.FeatureCollection(\"projects/GEE_CSP/pf-bobwhite/grid_5km\")\n",
    "\n",
    "# Define a function to extract the centroid of a feature and create a new feature with that centroid as its geometry\n",
    "def get_centroid(feature):\n",
    "    keepProperties = ['grid_id_5k']\n",
    "    centroid = feature.geometry().centroid()\n",
    "    return ee.Feature(centroid).copyProperties(feature, keepProperties)\n",
    "\n",
    "# Map the get_centroid function over the FeatureCollection to create a new FeatureCollection containing just the centroids\n",
    "centroids = grid_5km.map(get_centroid)\n",
    "\n",
    "# Print the result\n",
    "print(centroids.first().getInfo())\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1: Feature extraction using reduceRegion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract RAP proportional cover to CSV - this exports just fine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Write function to perform the raster extraction (for each raster) -- importantly set scale to the native resolution of whatever raster you're extracting from (e.g. 30m for RAP, 250m for LUI, etc.)\n",
    "def extract_rap_values(feature):\n",
    "  # Get the geometry of the feature\n",
    "  geometry = feature.geometry()\n",
    "\n",
    "  # Extract the raster values for the feature\n",
    "  values = rap_cover_all_small.reduceRegion(\n",
    "      reducer=ee.Reducer.mean(),\n",
    "      geometry=geometry,\n",
    "      scale=30)\n",
    "\n",
    "  # Set the values as properties of the feature\n",
    "  return feature.set(values)\n",
    "\n",
    "# Map the extract_values function over the feature collection\n",
    "rap_results = centroids.map(extract_rap_values)\n",
    "\n",
    "\n",
    "# Export the feature collection as a CSV file\n",
    "task = ee.batch.Export.table.toDrive(\n",
    "    collection=rap_results,\n",
    "    description='RAP-export',\n",
    "    folder='GEE_exports',\n",
    "    fileNamePrefix='RAP_5km',\n",
    "    fileFormat='CSV')\n",
    "task.start()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract gradient metric values to csv - ARGH I CANNOT GET THIS TO EXPORT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_gradient_values(feature):\n",
    "  # Get the geometry of the feature\n",
    "  geometry = feature.geometry()\n",
    "\n",
    "  # Extract the raster values for the feature\n",
    "  values = sa_img.reduceRegion(\n",
    "      reducer=ee.Reducer.mean(),\n",
    "      geometry=geometry)\n",
    "  # Set the values as properties of the feature\n",
    "  return feature.set(values)\n",
    "\n",
    "gradient_results = centroids.map(extract_gradient_values)\n",
    "\n",
    "# Export the feature collection as a CSV file\n",
    "task = ee.batch.Export.table.toDrive(\n",
    "    collection=gradient_results,\n",
    "    description='RAP-SA-export',\n",
    "    folder='GEE_exports',\n",
    "    fileNamePrefix='RAP_SA_5km',\n",
    "    fileFormat='CSV')\n",
    "task.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract DAYMET climate values to csv - ARGH I CANNOT GET THIS TO EXPORT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_climate_values(feature):\n",
    "  # Get the geometry of the feature\n",
    "  geometry = feature.geometry()\n",
    "\n",
    "  # Extract the raster values for the feature\n",
    "  values = climate_small.reduceRegion(\n",
    "      reducer=ee.Reducer.mean(),\n",
    "      geometry=geometry)\n",
    "  # Set the values as properties of the feature\n",
    "  return feature.set(values)\n",
    "\n",
    "climate_results = centroids.map(extract_climate_values)\n",
    "\n",
    "# Export the feature collection as a CSV file\n",
    "task = ee.batch.Export.table.toDrive(\n",
    "    collection=climate_results,\n",
    "    description='daymet-climate-export',\n",
    "    folder='GEE_exports',\n",
    "    fileNamePrefix='daymet_climate_5km',\n",
    "    fileFormat='CSV')\n",
    "task.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "722949c11c1062be71c011a99f617ef2cb85f305dcd033156e357c49092a513e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
