{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deriving covariates across the northern bobwhite range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = date.today()\n",
    "import ee\n",
    "import math\n",
    "import geemap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# Initialize ee and authenticate \n",
    "#ee.Authenticate()\n",
    "ee.Initialize()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Important Information\n",
    "\n",
    "## Script name: \n",
    "\n",
    "## Purpose of script:\n",
    "This is a preliminary script for deriving covariates across the northern bobwhite range for use in the construction of a species distribution model.\n",
    "## Author: \n",
    "Patrick Freeman (CSP)\n",
    "## Date Created: \n",
    "04/25/23\n",
    "## Date last modified:\n",
    "05/16/2023\n",
    "## Email: \n",
    "patrick[at]csp-inc.org\n",
    "## ---------------------------\n",
    "## Notes:\n",
    "\n",
    "## ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install geemap module as needed\n",
    "#!pip install geemap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ee\n",
    "import geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=Fa6urBC6KRVuV9LdYT4YOwdkiBylmdIGcAx0eM6Bd_g&tc=EIGykcAavMqyK6N6nZwYPsfrSYQYo0STyEn7ZvkHc6Y&cc=rh_5mX1KYr6ReQuPAAQDmBkgw2kS-zG07MWjfSpmcao>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=Fa6urBC6KRVuV9LdYT4YOwdkiBylmdIGcAx0eM6Bd_g&tc=EIGykcAavMqyK6N6nZwYPsfrSYQYo0STyEn7ZvkHc6Y&cc=rh_5mX1KYr6ReQuPAAQDmBkgw2kS-zG07MWjfSpmcao</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "\n",
    "# Focal mean\n",
    "def focal_mean(image, radius, unit, name):\n",
    "    names = image.bandNames().getInfo()\n",
    "    new_names = [s + name for s in names]\n",
    "    return image.reduceNeighborhood(kernel = ee.Kernel.circle(radius, unit),\n",
    "                                    reducer = ee.Reducer.mean()).rename(new_names)\n",
    "\n",
    "# Focal median\n",
    "def focal_median(image, radius, unit):\n",
    "    return image.reduceNeighborhood(kernel = ee.Kernel.circle(radius, unit),\n",
    "                                    reducer = ee.Reducer.median())\n",
    "    \n",
    "# Focal SD\n",
    "def focal_sd(image, radius, unit):\n",
    "    return image.reduceNeighborhood(kernel = ee.Kernel.circle(radius, unit),\n",
    "                                    reducer = ee.Reducer.stdDev())\n",
    "\n",
    "# Focal sum\n",
    "def focal_sum(image, radius, unit):\n",
    "    return image.reduceNeighborhood(kernel = ee.Kernel.circle(radius, unit, False),\n",
    "                                    reducer = ee.Reducer.sum())\n",
    "\n",
    "# Focal count\n",
    "def focal_count(image, radius, unit):\n",
    "    return image.reduceNeighborhood(kernel = ee.Kernel.circle(radius, unit, False),\n",
    "                                    reducer = ee.Reducer.count())\n",
    "    \n",
    "# Percent cover\n",
    "def percent_cov(image, radius, unit, name):\n",
    "    names = image.bandNames().getInfo()\n",
    "    new_names = [s + name for s in names]\n",
    "    isum = focal_sum(image, radius, unit)\n",
    "    icount = focal_count(image, radius, unit)\n",
    "    return isum.divide(icount).rename(new_names)\n",
    "\n",
    "#----------------------------------------\n",
    "# FUNCTIONS\n",
    "\n",
    "# Focal mean\n",
    "def focal_mean(image, radius, unit, name):\n",
    "    names = image.bandNames().getInfo()\n",
    "    new_names = [s + name for s in names]\n",
    "    return image.reduceNeighborhood(kernel = ee.Kernel.circle(radius, unit),\n",
    "                                    reducer = ee.Reducer.mean()).rename(new_names)\n",
    "\n",
    "# Focal median\n",
    "def focal_median(image, radius, unit):\n",
    "    return image.reduceNeighborhood(kernel = ee.Kernel.circle(radius, unit),\n",
    "                                    reducer = ee.Reducer.median())\n",
    "    \n",
    "# Focal SD\n",
    "def focal_sd(image, radius, unit):\n",
    "    return image.reduceNeighborhood(kernel = ee.Kernel.circle(radius, unit),\n",
    "                                    reducer = ee.Reducer.stdDev())\n",
    "\n",
    "# Focal sum\n",
    "def focal_sum(image, radius, unit):\n",
    "    return image.reduceNeighborhood(kernel = ee.Kernel.circle(radius, unit, False),\n",
    "                                    reducer = ee.Reducer.sum())\n",
    "\n",
    "# Focal count\n",
    "def focal_count(image, radius, unit):\n",
    "    return image.reduceNeighborhood(kernel = ee.Kernel.circle(radius, unit, False),\n",
    "                                    reducer = ee.Reducer.count())\n",
    "    \n",
    "# Percent cover\n",
    "def percent_cov(image, radius, unit, name):\n",
    "    names = image.bandNames().getInfo()\n",
    "    new_names = [s + name for s in names]\n",
    "    isum = focal_sum(image, radius, unit)\n",
    "    icount = focal_count(image, radius, unit)\n",
    "    return isum.divide(icount).rename(new_names)\n",
    "\n",
    "# Vector ruggedness measure\n",
    "def compute_vrm(slope_img, aspect_img, radius, units):\n",
    "    slope_sine = slope_img.sin()\n",
    "    x_sum_sq = focal_sum(slope_sine.multiply(aspect_img.sin()), radius, units).pow(2)\n",
    "    y_sum_sq = focal_sum(slope_sine.multiply(aspect_img.cos()), radius, units).pow(2)\n",
    "    z_sum_sq = focal_sum(slope_img.cos(), radius, units).pow(2)\n",
    "    n = focal_sum(ee.Image(1), radius, units)\n",
    "    r = x_sum_sq.add(y_sum_sq).add(z_sum_sq).sqrt()\n",
    "    vrm_img = ee.Image(1).subtract(r.divide(n))\n",
    "    return vrm_img\n",
    "\n",
    "def toFloat(img):\n",
    "    return img.float()\n",
    "#----------------------------------------\n",
    "\n",
    "def toFloat(img):\n",
    "    return img.float()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set aoi, spatial scale and projection of export, and smoothing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bring in buffered range map as 'region' \n",
    "region = ee.FeatureCollection('projects/GEE_CSP/pf-bobwhite/bobwhite_model_states')\n",
    "geometry = ee.Feature(ee.FeatureCollection(region).first())\n",
    "conus_geom = ee.FeatureCollection(\"projects/GEE_CSP/thirty-by-thirty/aoi_conus\")\n",
    "conus_img = ee.Image(\"projects/GEE_CSP/thirty-by-thirty/aoi_conus_mask\")\n",
    "\n",
    "# export scale and projection\n",
    "scale = 270\n",
    "projection = ee.Projection('EPSG:5070') # stand-in for now. Figure out best projection to use \n",
    "\n",
    "### Load sampling grid\n",
    "grid_5km = ee.FeatureCollection(\"projects/GEE_CSP/pf-bobwhite/grid_5km\")\n",
    "\n",
    "# Define a function to extract the centroid of a feature and create a new feature with that centroid as its geometry\n",
    "def get_centroid(feature):\n",
    "    keepProperties = ['grid_id_5k']\n",
    "    centroid = feature.geometry().centroid()\n",
    "    return ee.Feature(centroid).copyProperties(feature, keepProperties)\n",
    "\n",
    "# Map the get_centroid function over the FeatureCollection to create a new FeatureCollection containing just the centroids\n",
    "centroids = grid_5km.map(get_centroid)\n",
    "\n",
    "# Choose radii for summarizing covariates\n",
    "rad_large = 10000\n",
    "rad_small = 5000\n",
    "name_large = \"_10km\"\n",
    "name_small = \"_5km\"\n",
    "\n",
    "## Plot to check \n",
    "#Map = geemap.Map(center=(40, -100), zoom=4)\n",
    "#Map.addLayer(geometry, {}, \"Model states\", True)\n",
    "#Map\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSP-derived land use intensity layers related to agriculture, transportation, urban development, and energy infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lui Band names: ['Ag', 'Urban', 'Transport', 'Energy']\n",
      "lui_focal_means Band names: ['Ag_10km', 'Urban_10km', 'Transport_10km', 'Energy_10km']\n"
     ]
    }
   ],
   "source": [
    "lui = ee.Image(\"projects/GEE_CSP/aft-connectivity/Land-use-intensity-multiband-focal-sp-250m-20220123\")\n",
    "\n",
    "### Get the band names as a check \n",
    "lui_names = lui.bandNames()\n",
    "print('lui Band names:', lui_names.getInfo())  # ee.List of band names\n",
    "lui_focal_means_large = focal_mean(lui, rad_large, \"meters\", name_large).updateMask(conus_img).clip(geometry)\n",
    "lui_focal_means_small = focal_mean(lui, rad_small, \"meters\", name_small).updateMask(conus_img).clip(geometry)\n",
    "\n",
    "### Get the band names as a check \n",
    "lui_focal_means_names = lui_focal_means_large.bandNames()\n",
    "print('lui_focal_means Band names:', lui_focal_means_names.getInfo())  # ee.List of band names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate percent cover of row crop from NLCD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products: ['2001', '2004', '2006', '2008', '2011', '2013', '2016', '2019']\n",
      "rowcrop_pcov_all_band_names Band names: ['rowcrop_16_pcov_5km', 'rowcrop_19_pcov_5km']\n"
     ]
    }
   ],
   "source": [
    "### Load all NLCD layers from data release \n",
    "nlcd_all = ee.ImageCollection('USGS/NLCD_RELEASES/2019_REL/NLCD')\n",
    "\n",
    "### The collection contains images for multiple years and regions in the USA.\n",
    "print('Products:', nlcd_all.aggregate_array('system:index').getInfo())\n",
    "\n",
    "nlcd_16 = ee.ImageCollection(\"USGS/NLCD_RELEASES/2019_REL/NLCD\").filter(ee.Filter.eq('system:index', '2016')).first().select('landcover')\n",
    "nlcd_19 = ee.ImageCollection(\"USGS/NLCD_RELEASES/2019_REL/NLCD\").filter(ee.Filter.eq('system:index', '2019')).first().select('landcover')\n",
    "\n",
    "ag_16 = ee.Image(0).where(nlcd_16.eq(82), 1).rename('rowcrop_16')\n",
    "ag_19 = ee.Image(0).where(nlcd_19.eq(82), 1).rename('rowcrop_19')\n",
    "\n",
    "ag_all = ee.Image([ag_16, ag_19])\n",
    "\n",
    "rowcrop_pcov_all = percent_cov(ag_all, rad_small, 'meters', '_pcov' + name_small).clip(geometry)\n",
    "\n",
    "rowcrop_pcov_all_band_names = rowcrop_pcov_all.bandNames()\n",
    "print('rowcrop_pcov_all_band_names Band names:', rowcrop_pcov_all_band_names.getInfo())  # ee.List of band names\n",
    "\n",
    "rowcrop_pcov_avg = rowcrop_pcov_all.reduce(ee.Reducer.mean()).rename(['NLCD_1619_mean_rowcropPcov'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export ag proportional cover as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Write function to perform the raster extraction (for each raster) -- importantly set scale to the native resolution of whatever raster you're extracting from (e.g. 30m for RAP, 250m for LUI, etc.)\n",
    "def extract_agpcov_values(feature):\n",
    "  # Get the geometry of the feature\n",
    "  geometry = feature.geometry()\n",
    "\n",
    "  # Extract the raster values for the feature\n",
    "  values = rowcrop_pcov_avg.reduceRegion(\n",
    "      reducer=ee.Reducer.mean(),\n",
    "      geometry=geometry,\n",
    "      scale=30)\n",
    "\n",
    "  # Set the values as properties of the feature\n",
    "  return feature.set(values)\n",
    "\n",
    "# Map the extract_values function over the feature collection\n",
    "agpcov_results = centroids.map(extract_agpcov_values)\n",
    "\n",
    "\n",
    "# Export the feature collection as a CSV file\n",
    "task = ee.batch.Export.table.toDrive(\n",
    "    collection=agpcov_results,\n",
    "    description='AgPCOV-export',\n",
    "    folder='GEE-exports',\n",
    "    fileNamePrefix='AgPCov_5km_1619',\n",
    "    fileFormat='CSV')\n",
    "task.start()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAP Proportional Cover - first calculate multi-year averages and apply smoothing within 5km smoothing windows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "band_names: ['2016_AFG', '2016_PFG', '2016_SHR', '2016_TRE', '2016_BGR', '2017_AFG', '2017_PFG', '2017_SHR', '2017_TRE', '2017_BGR', '2018_AFG', '2018_PFG', '2018_SHR', '2018_TRE', '2018_BGR', '2019_AFG', '2019_PFG', '2019_SHR', '2019_TRE', '2019_BGR', '2020_AFG', '2020_PFG', '2020_SHR', '2020_TRE', '2020_BGR', '2021_AFG', '2021_PFG', '2021_SHR', '2021_TRE', '2021_BGR']\n",
      "tree_mean_smooth Band names: ['RAP_TRE_1621_mean_5km']\n"
     ]
    }
   ],
   "source": [
    "geometry = ee.Feature(ee.FeatureCollection(\"projects/GEE_CSP/pf-bobwhite/bobwhite_model_states\").first());\n",
    "##---------- Define the years that you want to export --------------\n",
    "##---------- End year is inclusive in this case  ------------------\n",
    "yearStart = 2016\n",
    "yearEnd = 2021\n",
    "\n",
    "## -------------- Define the plant functional types (PFTs) that you want to export --------------\n",
    "## PFTs are \"AFGC\" (Annual forb and grass cover), \"BG\" (bare ground), \"LTR\" (litter), \n",
    "## \"PFGC\" (perennial forb and grass cover), \"SHR\" (shrub cover), and \"TREE\" (tree cover)\n",
    "## Select Annual forb and grass cover, perennial forb and grass cover, shrub cover, and tree cover \n",
    "PFTs = ee.List(['AFG', 'PFG', 'SHR', 'TRE', 'BGR'])\n",
    "\n",
    "cover = ee.ImageCollection(\"projects/rangeland-analysis-platform/vegetation-cover-v3\")\n",
    "## ------------- Select the PFTs for processing as defined by User  --------------\n",
    "cover_toExport = cover.select(PFTs).filter(ee.Filter.inList('year', ee.List([2016, 2017, 2018, 2019, 2020, 2021]))).toBands()\n",
    "\n",
    "band_names = cover_toExport.bandNames()\n",
    "print('band_names:', band_names.getInfo())  # ee.List of band names\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get mean value of each individual cover type across all years "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define string to match\n",
    "string_to_match = \"_TRE\"\n",
    "# Get the band names from the image\n",
    "band_names = cover_toExport.bandNames()\n",
    "# Filter the bands to select only the ones that contain the partial string\n",
    "tree_bands = band_names.filter(ee.Filter.stringContains(\"item\", string_to_match))\n",
    "# Select the TREE COVER bands from the image, calculate the multi-year mean, and apply the focal smooth operation\n",
    "tree_img = cover_toExport.select(tree_bands).reduce(ee.Reducer.mean()).rename(['RAP_TRE_1621_mean'])\n",
    "\n",
    "tree_mean_smooth = focal_mean(tree_img, rad_small, \"meters\", name_small).clip(geometry)\n",
    "tree_mean_smooth_band_names = tree_mean_smooth.bandNames()\n",
    "print('tree_mean_smooth Band names:', tree_mean_smooth_band_names.getInfo())  # ee.List of band names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select the SHRUB COVER bands from the image\n",
    "string_to_match = \"_SHR\"\n",
    "# Filter the bands to select only the ones that contain the partial string\n",
    "shrub_bands = band_names.filter(ee.Filter.stringContains(\"item\", string_to_match))\n",
    "# Select the SHRUB COVER bands from the image\n",
    "shrub_img = cover_toExport.select(shrub_bands).reduce(ee.Reducer.mean()).rename(['RAP_SHR_1621_mean'])\n",
    "\n",
    "shrub_mean_smooth = focal_mean(shrub_img, rad_small, \"meters\", name_small).clip(geometry)\n",
    "shrub_mean_smooth_band_names = shrub_mean_smooth.bandNames()\n",
    "print('shrub_mean_smooth Band names:', shrub_mean_smooth_band_names.getInfo())  # ee.List of band names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select the ANNUAL FORB AND GRASS COVER bands from the image\n",
    "string_to_match = \"_AFG\"\n",
    "# Filter the bands to select only the ones that contain the partial string\n",
    "afg_bands = band_names.filter(ee.Filter.stringContains(\"item\", string_to_match))\n",
    "afg_img = cover_toExport.select(afg_bands).reduce(ee.Reducer.mean()).rename(['RAP_AFG_1621_mean'])\n",
    "\n",
    "afg_mean_smooth = focal_mean(afg_img, rad_small, \"meters\", name_small).clip(geometry)\n",
    "afg_mean_smooth_band_names = afg_mean_smooth.bandNames()\n",
    "print('afg_mean_smooth Band names:', afg_mean_smooth_band_names.getInfo())  # ee.List of band names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select the PERENNIAL FORB AND GRASS COVER bands from the image\n",
    "string_to_match = \"_PFG\"\n",
    "# Filter the bands to select only the ones that contain the partial string\n",
    "pfg_bands = band_names.filter(ee.Filter.stringContains(\"item\", string_to_match))\n",
    "# Select the ANNUAL FORB AND GRASS COVER bands from the image\n",
    "pfg_img = cover_toExport.select(pfg_bands).reduce(ee.Reducer.mean()).rename(['RAP_PFG_1621_mean'])\n",
    "\n",
    "pfg_mean_smooth = focal_mean(pfg_img, rad_small, \"meters\", name_small).clip(geometry)\n",
    "pfg_mean_smooth_band_names = pfg_mean_smooth.bandNames()\n",
    "print('pfg_mean_smooth Band names:', pfg_mean_smooth_band_names.getInfo())  # ee.List of band names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select the BARE GROUND COVER bands from the image\n",
    "string_to_match = \"_BGR\"\n",
    "# Filter the bands to select only the ones that contain the partial string\n",
    "bgr_bands = band_names.filter(ee.Filter.stringContains(\"item\", string_to_match))\n",
    "# Select the ANNUAL FORB AND GRASS COVER bands from the image\n",
    "bgr_img = cover_toExport.select(bgr_bands).reduce(ee.Reducer.mean()).rename(['RAP_BGR_1621_mean'])\n",
    "\n",
    "bgr_mean_smooth = focal_mean(bgr_img, rad_small, \"meters\", name_small).clip(geometry)\n",
    "bgr_mean_smooth_band_names = bgr_mean_smooth.bandNames()\n",
    "print('bgr_mean_smooth Band names:', bgr_mean_smooth_band_names.getInfo())  # ee.List of band names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Smoothed RAP Values to Cell Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rap_img = ee.Image([bgr_mean_smooth, pfg_mean_smooth, afg_mean_smooth, shrub_mean_smooth, tree_mean_smooth])\n",
    "\n",
    "#### Write function to perform the raster extraction (for each raster) -- importantly set scale to the native resolution of whatever raster you're extracting from (e.g. 30m for RAP, 250m for LUI, etc.)\n",
    "def extract_rap_values(feature):\n",
    "  # Get the geometry of the feature\n",
    "  geometry = feature.geometry()\n",
    "\n",
    "  # Extract the raster values for the feature\n",
    "  values = final_rap_img.reduceRegion(\n",
    "      reducer=ee.Reducer.mean(),\n",
    "      geometry=geometry,\n",
    "      scale=30)\n",
    "\n",
    "  # Set the values as properties of the feature\n",
    "  return feature.set(values)\n",
    "\n",
    "# Map the extract_values function over the feature collection\n",
    "rap_results = centroids.map(extract_rap_values)\n",
    "\n",
    "\n",
    "# Export the feature collection as a CSV file\n",
    "task = ee.batch.Export.table.toDrive(\n",
    "    collection=rap_results,\n",
    "    description='RAP-export',\n",
    "    folder='GEE-exports',\n",
    "    fileNamePrefix='RAP_5km_smooth',\n",
    "    fileFormat='CSV')\n",
    "task.start()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect the raw (unsmoothed) multi-year average RAP cover images into a multi-band image for gradient analysis  - export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RAP_unsmoothed = ee.Image([tree_img, shrub_img, afg_img, pfg_img, bgr_img ])\n",
    "\n",
    "# Convert all to float-32\n",
    "RAP_unsmoothed = RAP_unsmoothed.float()\n",
    "scale=270\n",
    "task1 = ee.batch.Export.image.toDrive(image = RAP_unsmoothed,\n",
    "                                     folder = 'GEE-exports',\n",
    "                                     description = 'RAP-1621-mean-unsmoothed' + str(scale) + \"m\",\n",
    "                                     scale = scale,\n",
    "                                     region = geometry.geometry(),\n",
    "                                     maxPixels = 1e13,\n",
    "                                     crs = \"EPSG:5070\")\n",
    "task1.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate covariates from Daymet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load daymet dataset \n",
    "daymet_16 = ee.ImageCollection(\"NASA/ORNL/DAYMET_V4\").filter(ee.Filter.date('2016-01-01', '2016-12-31'))\n",
    "daymet_17 = ee.ImageCollection(\"NASA/ORNL/DAYMET_V4\").filter(ee.Filter.date('2017-01-01', '2017-12-31'))\n",
    "daymet_18 = ee.ImageCollection(\"NASA/ORNL/DAYMET_V4\").filter(ee.Filter.date('2018-01-01', '2018-12-31'))\n",
    "daymet_19 = ee.ImageCollection(\"NASA/ORNL/DAYMET_V4\").filter(ee.Filter.date('2019-01-01', '2019-12-31'))\n",
    "daymet_21 = ee.ImageCollection(\"NASA/ORNL/DAYMET_V4\").filter(ee.Filter.date('2021-01-01', '2021-12-31'))\n",
    "\n",
    "daymet_1621 = ee.ImageCollection(\"NASA/ORNL/DAYMET_V4\").filter(ee.Filter.date('2016-01-01', '2021-12-31'))\n",
    "tmax_1621 = daymet_1621.select(\"tmax\").mean().rename(['tmax_1621_mean'])\n",
    "tmin_1621 = daymet_1621.select(\"tmin\").mean().rename(['tmin_1621_mean'])\n",
    "prcp_1621 = daymet_1621.select(\"prcp\").mean().rename(['prcp_1621_mean'])\n",
    "swe_1621 = daymet_1621.select(\"swe\").mean().rename(['swe_1621_mean'])\n",
    "\n",
    "climate_1621 = ee.Image([tmax_1621, tmin_1621, prcp_1621, swe_1621])\n",
    "climate_1621_small = focal_mean(climate_1621, rad_small, \"meters\", name_small).updateMask(conus_img).clip(geometry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert all to float-32\n",
    "climate_1621_small = climate_1621_small.float()\n",
    "scale=270\n",
    "task1 = ee.batch.Export.image.toDrive(image = climate_1621_small,\n",
    "                                     folder = 'GEE-exports',\n",
    "                                     description = 'climate-1621-mean-smoothed' + str(scale) + \"m\",\n",
    "                                     scale = scale,\n",
    "                                     region = geometry.geometry(),\n",
    "                                     maxPixels = 1e13,\n",
    "                                     crs = \"EPSG:5070\")\n",
    "task1.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terrain and Topography variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------\n",
    "# TERRAIN VARIABLES\n",
    "# Create some topographic viables\n",
    "dsm = ee.ImageCollection(\"JAXA/ALOS/AW3D30/V3_2\") # Digital surface model. Native res 30m\n",
    "projElev = dsm.first().select(0).projection()\n",
    "elev = dsm.select(\"DSM\").mosaic().setDefaultProjection(projElev).rename('elevation') # Elevation\n",
    "slope = ee.Terrain.slope(elev).rename('slope') # Slope\n",
    "aspect = ee.Terrain.aspect(elev).rename('aspect') # Aspect\n",
    "# Get vector ruggedness metric\n",
    "window_radius = 1000\n",
    "slopeRad = slope.multiply(ee.Number(math.pi).divide(180))\n",
    "aspectRad = slope.multiply(ee.Number(math.pi).divide(180))\n",
    "vrm = compute_vrm(slopeRad, aspectRad, window_radius, \"meters\").rename('vrm')\n",
    "chili = ee.Image(\"CSP/ERGo/1_0/US/CHILI\").rename('CHILI')\n",
    "\n",
    "# Combine and smooth\n",
    "terrain_all = ee.Image([elev, slope, aspect, vrm, chili])\n",
    "terrain_small = focal_mean(terrain_all, rad_small, \"meters\", name_small)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract terrain variables to grid cell centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Write function to perform the raster extraction (for each raster) -- importantly set scale to the native resolution of whatever raster you're extracting from (e.g. 30m for RAP, 250m for LUI, etc.)\n",
    "def extract_terrain_values(feature):\n",
    "  # Get the geometry of the feature\n",
    "  geometry = feature.geometry()\n",
    "\n",
    "  # Extract the raster values for the feature\n",
    "  values = terrain_small.reduceRegion(\n",
    "      reducer=ee.Reducer.mean(),\n",
    "      geometry=geometry,\n",
    "      scale=30)\n",
    "\n",
    "  # Set the values as properties of the feature\n",
    "  return feature.set(values)\n",
    "\n",
    "# Map the extract_values function over the feature collection\n",
    "terrain_results = centroids.map(extract_terrain_values)\n",
    "\n",
    "\n",
    "# Export the feature collection as a CSV file\n",
    "task = ee.batch.Export.table.toDrive(\n",
    "    collection=terrain_results,\n",
    "    description='Terrain-export',\n",
    "    folder='GEE-exports',\n",
    "    fileNamePrefix='terrain_5km_smooth',\n",
    "    fileFormat='CSV')\n",
    "task.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parking lot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all to float-32\n",
    "covs_all = covs_all.float().clip(geometry)\n",
    "rd_dist_ready = rd_dist.float().clip(geometry)\n",
    "\n",
    "task1 = ee.batch.Export.image.toDrive(image = covs_all,\n",
    "                                     folder = 'mule-deer-covs',\n",
    "                                     description = 'mule-deer-covs-final-' + str(scale) + \"m\",\n",
    "                                     scale = scale,\n",
    "                                     region = geometry.geometry(),\n",
    "                                     maxPixels = 1e13,\n",
    "                                     crs = \"EPSG:26911\")\n",
    "task1.start()\n",
    "\n",
    "#task2 = ee.batch.Export.image.toDrive(image = rd_dist_ready,\n",
    "#                                     folder = 'mule-deer-covs',\n",
    "#                                     description = 'mule-deer-road-distance-present-90m',\n",
    "#                                     scale = 90,\n",
    "#                                     region = geometry.geometry(),\n",
    "#                                     maxPixels = 1e13,\n",
    "#                                     crs = \"EPSG:26911\")\n",
    "#task2.start()\n",
    "\n",
    "#task1 = ee.batch.Export.image.toCloudStorage(image = covs_all,\n",
    "#                                     folder = 'mule-deer-covs',\n",
    "#                                     description = 'mule-deer-covs-' + str(scale) + \"m\",\n",
    "#                                    bucket: 'blm-connectivity/data/muledeer/source'\n",
    "#                                     fileNamePrefix: 'image_export'\n",
    "#                                    scale = scale,\n",
    "#                                     region = geometry,\n",
    "#                                     maxPixels = 1e13,\n",
    "#                                     crs = \"EPSG:26911\")\n",
    "\n",
    "# Road covs\n",
    "# These need to be exported at coarser resolution to deal with \n",
    "# max kernel size issues and need to cover full study area\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "722949c11c1062be71c011a99f617ef2cb85f305dcd033156e357c49092a513e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
